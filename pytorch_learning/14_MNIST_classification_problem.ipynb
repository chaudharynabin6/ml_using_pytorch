{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is MNIST dataset?\n",
    "Image result for mnist dataset\n",
    "The MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset. It is a dataset of 60,000 small square 28Ã—28 pixel grayscale images of handwritten single digits between 0 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[] config\\n[] hyper parameter \\n[] dataset\\n[] dataloader\\n[] data visualization\\n[] model designing\\n[] criterion and optimizer\\n[] training loop (with batch)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "[] config\n",
    "[] hyper parameter \n",
    "[] dataset\n",
    "[] dataloader\n",
    "[] data visualization\n",
    "[] model designing\n",
    "[] criterion and optimizer\n",
    "[] training loop (with batch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision  import datasets,transforms\n",
    "from torch.utils.data import dataset,dataloader\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device used: cpu\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "\n",
    "# device config\n",
    "\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device=device_name)\n",
    "print(f\"device used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "\n",
    "input_layer_nodes = 28*28 # input grid size\n",
    "\n",
    "hidden_layer_nodes = 100 # used for improving classification\n",
    "\n",
    "output_layer_nodes = 10 # total number of classes\n",
    "\n",
    "batch_size = 64 # fast training use 32 or 64\n",
    "\n",
    "learning_rate = 0.01 # learning rate\n",
    "\n",
    "number_of_epochs = 2 # number of epochs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape():\n",
    "\n",
    "    def __init__(self,row,col) -> None:\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "    \n",
    "    def __call__(self,single_sample):\n",
    "        # print(single_sample)\n",
    "        features = single_sample\n",
    "\n",
    "        features  = features.view(-1,self.row*self.col)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "composed_transform = transforms.Compose(transforms=[\n",
    "    transforms.ToTensor(),\n",
    "    Reshape(28,28)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data/mnist/\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform= composed_transform\n",
    "    )\n",
    "# train_dataset.data.shape\n",
    "# train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = datasets.MNIST(\n",
    "    root='./data/mnist/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.transforms.ToTensor()\n",
    ")\n",
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataloader.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "test_loader = dataloader.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size : torch.Size([64, 1, 784])\n",
      "label size: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "all_sample = iter(train_loader)\n",
    "\n",
    "first_sample = all_sample.next()\n",
    "\n",
    "sample,label = first_sample\n",
    "\n",
    "print(f\"sample size : {sample.shape}\")\n",
    "print(f\"label size: {label.shape}\")\n",
    "\n",
    "# print(f\"sample : {sample}\")\n",
    "# print(f\"label: {label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plot.subplot(2,3,i+1)\n",
    "    plot.imshow(sample[i][0].view(28,28),cmap=\"gray\")\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "\n",
    "class NeuralNetork(nn.Module):\n",
    "\n",
    "    def __init__(self,input_layer_nodes,hidden_layer_nodes,output_layer_nodes) -> None:\n",
    "        super(NeuralNetork,self).__init__()\n",
    "\n",
    "    \n",
    "        self.input_layer = nn.Linear(in_features=input_layer_nodes,out_features=hidden_layer_nodes)\n",
    "        \n",
    "        self.relu_activation = nn.ReLU()\n",
    "\n",
    "        self.hiden_layer = nn.Linear(in_features=hidden_layer_nodes,out_features=output_layer_nodes)\n",
    "\n",
    "        # no softmax\n",
    "\n",
    "    \n",
    "    def forward(self,batch_samples):\n",
    "        out = batch_samples.view(-1,28*28)\n",
    "        # print(out.shape)\n",
    "        out = self.input_layer(out)\n",
    "\n",
    "        out = self.relu_activation(out)\n",
    "\n",
    "        out = self.hiden_layer(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = NeuralNetork(input_layer_nodes=input_layer_nodes,hidden_layer_nodes=hidden_layer_nodes,output_layer_nodes=output_layer_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# criterian and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- iteration --100 ----------------\n",
      "loss: 0.145\n",
      "-------------------- iteration --200 ----------------\n",
      "loss: 0.192\n",
      "-------------------- iteration --300 ----------------\n",
      "loss: 0.118\n",
      "-------------------- iteration --400 ----------------\n",
      "loss: 0.092\n",
      "-------------------- iteration --500 ----------------\n",
      "loss: 0.148\n",
      "-------------------- iteration --600 ----------------\n",
      "loss: 0.229\n",
      "-------------------- iteration --700 ----------------\n",
      "loss: 0.179\n",
      "-------------------- iteration --800 ----------------\n",
      "loss: 0.193\n",
      "-------------------- iteration --900 ----------------\n",
      "loss: 0.090\n",
      "-------------------- iteration --100 ----------------\n",
      "loss: 0.103\n",
      "-------------------- iteration --200 ----------------\n",
      "loss: 0.178\n",
      "-------------------- iteration --300 ----------------\n",
      "loss: 0.255\n",
      "-------------------- iteration --400 ----------------\n",
      "loss: 0.052\n",
      "-------------------- iteration --500 ----------------\n",
      "loss: 0.015\n",
      "-------------------- iteration --600 ----------------\n",
      "loss: 0.167\n",
      "-------------------- iteration --700 ----------------\n",
      "loss: 0.103\n",
      "-------------------- iteration --800 ----------------\n",
      "loss: 0.018\n",
      "-------------------- iteration --900 ----------------\n",
      "loss: 0.128\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(number_of_epochs):\n",
    "\n",
    "    for i,(sample,labels) in enumerate(train_loader):\n",
    "        # making grad zero for each next batch size\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # sample = sample.view(-1,28*28).to(device)\n",
    "        # print(sample.shape)\n",
    "        sample = sample.to(device)\n",
    "        # print(sample.shape)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        y_predict = model(sample)\n",
    "\n",
    "        loss = criterian(y_predict,labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            \n",
    "            print(f\"-------------------- iteration --{i+1} ----------------\")\n",
    "\n",
    "            print(f\"loss: {loss:.03f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.963699996471405\n"
     ]
    }
   ],
   "source": [
    "n_samples = 0\n",
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for (batch_samples,label) in iter(test_loader):\n",
    "\n",
    "        batch_samples = batch_samples.to(device)\n",
    "        y_predict = model(batch_samples)\n",
    "\n",
    "        _,prediction = torch.max(y_predict,dim=1)\n",
    "\n",
    "        n_correct += (prediction == label).sum()\n",
    "\n",
    "        n_samples += batch_samples.shape[0]\n",
    "\n",
    "    acc = n_correct/ n_samples\n",
    "\n",
    "print(f\"accuracy: {acc}\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610c9d3786a5bcd122c38aa183fd980592c5db79f4cee84c2a544f8f000107e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
