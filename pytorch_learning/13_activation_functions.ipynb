{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why activation functions?\n",
    "![why_activation_functions](assets/why_activation_functions.png)\n",
    "![why_activation_functions](assets/why_activation_functions_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most popular activation functions are\n",
    "\n",
    "![most_popular_activation_functions](assets/most_popular_activation_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. step function\n",
    "\n",
    "![step function](assets/step_function.png)\n",
    "\n",
    "### 2. Sigmoid\n",
    "![sigmoid](assets/sigmoid_function.png)\n",
    "\n",
    "### 3. TanH\n",
    "![TanH](assets/most_popular_activation_functions.png)\n",
    "\n",
    "### 4. ReLU\n",
    "![ReLU](assets/relu.png)\n",
    "\n",
    "### 5. Leaky ReLU\n",
    "![Leaky ReLU](assets/leaky_relu.png)\n",
    "\n",
    "### 6. Softmax\n",
    "![softmax](assets/softmax_activation.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# option 1\n",
    "\n",
    "class NeuralNetwork1(nn.Module):\n",
    "\n",
    "    def __init__(self,num_of_input_features) -> None:\n",
    "        super(NeuralNetwork1,self).__init__()\n",
    "\n",
    "        self.input = nn.Linear(in_features=num_of_input_features,out_features=5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.hidden = nn.Linear(in_features=5,out_features=2)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        out = self.input(x)\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.hidden(out)\n",
    "\n",
    "        out = self.softmax(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5258, 0.4742],\n",
      "        [0.5880, 0.4120],\n",
      "        [0.6219, 0.3781]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = [\n",
    "    [1,2,3],\n",
    "    [3,4,5],\n",
    "    [9,8,7]\n",
    "]\n",
    "# cause error because of input shape required is (n_sample,10)\n",
    "model = NeuralNetwork1(num_of_input_features=3)\n",
    "X = torch.tensor(X,dtype=torch.float32)\n",
    "y_predict = model(X)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5074, 0.4926],\n",
      "        [0.5551, 0.4449],\n",
      "        [0.5562, 0.4438],\n",
      "        [0.5166, 0.4834],\n",
      "        [0.5413, 0.4587],\n",
      "        [0.5529, 0.4471],\n",
      "        [0.5234, 0.4766],\n",
      "        [0.5398, 0.4602],\n",
      "        [0.5731, 0.4269],\n",
      "        [0.5065, 0.4935],\n",
      "        [0.5301, 0.4699],\n",
      "        [0.5499, 0.4501],\n",
      "        [0.5717, 0.4283],\n",
      "        [0.5469, 0.4531],\n",
      "        [0.5253, 0.4747],\n",
      "        [0.5306, 0.4694],\n",
      "        [0.4766, 0.5234],\n",
      "        [0.5141, 0.4859],\n",
      "        [0.5430, 0.4570],\n",
      "        [0.5165, 0.4835],\n",
      "        [0.4727, 0.5273],\n",
      "        [0.5828, 0.4172],\n",
      "        [0.5327, 0.4673],\n",
      "        [0.5771, 0.4229],\n",
      "        [0.5300, 0.4700],\n",
      "        [0.6003, 0.3997],\n",
      "        [0.5251, 0.4749],\n",
      "        [0.5497, 0.4503],\n",
      "        [0.5349, 0.4651],\n",
      "        [0.5798, 0.4202],\n",
      "        [0.5670, 0.4330],\n",
      "        [0.5217, 0.4783],\n",
      "        [0.5779, 0.4221],\n",
      "        [0.5557, 0.4443],\n",
      "        [0.5265, 0.4735],\n",
      "        [0.5420, 0.4580],\n",
      "        [0.5349, 0.4651],\n",
      "        [0.5763, 0.4237],\n",
      "        [0.5538, 0.4462],\n",
      "        [0.5602, 0.4398],\n",
      "        [0.5656, 0.4344],\n",
      "        [0.5246, 0.4754],\n",
      "        [0.5105, 0.4895],\n",
      "        [0.5154, 0.4846],\n",
      "        [0.5305, 0.4695],\n",
      "        [0.5667, 0.4333],\n",
      "        [0.5357, 0.4643],\n",
      "        [0.5424, 0.4576],\n",
      "        [0.5673, 0.4327],\n",
      "        [0.5521, 0.4479],\n",
      "        [0.5697, 0.4303],\n",
      "        [0.5218, 0.4782],\n",
      "        [0.5322, 0.4678],\n",
      "        [0.5238, 0.4762],\n",
      "        [0.4884, 0.5116],\n",
      "        [0.5429, 0.4571],\n",
      "        [0.5048, 0.4952],\n",
      "        [0.5538, 0.4462],\n",
      "        [0.5728, 0.4272],\n",
      "        [0.5221, 0.4779],\n",
      "        [0.5560, 0.4440],\n",
      "        [0.6112, 0.3888],\n",
      "        [0.4526, 0.5474],\n",
      "        [0.5837, 0.4163],\n",
      "        [0.5810, 0.4190],\n",
      "        [0.5802, 0.4198],\n",
      "        [0.4714, 0.5286],\n",
      "        [0.5386, 0.4614],\n",
      "        [0.5182, 0.4818],\n",
      "        [0.5632, 0.4368],\n",
      "        [0.5054, 0.4946],\n",
      "        [0.5738, 0.4262],\n",
      "        [0.6024, 0.3976],\n",
      "        [0.5434, 0.4566],\n",
      "        [0.5222, 0.4778],\n",
      "        [0.5490, 0.4510],\n",
      "        [0.5464, 0.4536],\n",
      "        [0.5949, 0.4051],\n",
      "        [0.4570, 0.5430],\n",
      "        [0.5257, 0.4743],\n",
      "        [0.5591, 0.4409],\n",
      "        [0.5443, 0.4557],\n",
      "        [0.6053, 0.3947],\n",
      "        [0.4977, 0.5023],\n",
      "        [0.5733, 0.4267],\n",
      "        [0.5754, 0.4246],\n",
      "        [0.5881, 0.4119],\n",
      "        [0.5416, 0.4584],\n",
      "        [0.5409, 0.4591],\n",
      "        [0.5550, 0.4450],\n",
      "        [0.5864, 0.4136],\n",
      "        [0.5175, 0.4825],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.5432, 0.4568],\n",
      "        [0.5892, 0.4108],\n",
      "        [0.5360, 0.4640],\n",
      "        [0.5384, 0.4616],\n",
      "        [0.5423, 0.4577],\n",
      "        [0.5521, 0.4479],\n",
      "        [0.5545, 0.4455]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork1(num_of_input_features=10)\n",
    "X = torch.rand(size=(100,10),dtype=torch.float32)\n",
    "y_predict = model(X)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# if activation functions not available in torch use this\n",
    "import torch.nn.functional as F\n",
    "# option 1\n",
    "\n",
    "class NeuralNetwork1(nn.Module):\n",
    "\n",
    "    def __init__(self,num_of_input_features) -> None:\n",
    "        super(NeuralNetwork1,self).__init__()\n",
    "\n",
    "        self.input = nn.Linear(in_features=num_of_input_features,out_features=5)\n",
    "\n",
    "     \n",
    "\n",
    "        self.hidden = nn.Linear(in_features=5,out_features=2)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        out = self.input(x)\n",
    "\n",
    "        out = torch.relu(out)\n",
    "\n",
    "        out = self.hidden(out)\n",
    "\n",
    "        out = F.softmax(out,dim=1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5131, 0.4869],\n",
      "        [0.5078, 0.4922],\n",
      "        [0.5051, 0.4949],\n",
      "        [0.5039, 0.4961],\n",
      "        [0.5088, 0.4912],\n",
      "        [0.5143, 0.4857],\n",
      "        [0.5174, 0.4826],\n",
      "        [0.5146, 0.4854],\n",
      "        [0.5283, 0.4717],\n",
      "        [0.4983, 0.5017],\n",
      "        [0.5144, 0.4856],\n",
      "        [0.5113, 0.4887],\n",
      "        [0.5222, 0.4778],\n",
      "        [0.5162, 0.4838],\n",
      "        [0.5157, 0.4843],\n",
      "        [0.5255, 0.4745],\n",
      "        [0.5054, 0.4946],\n",
      "        [0.5109, 0.4891],\n",
      "        [0.5096, 0.4904],\n",
      "        [0.5076, 0.4924],\n",
      "        [0.4960, 0.5040],\n",
      "        [0.4814, 0.5186],\n",
      "        [0.5160, 0.4840],\n",
      "        [0.5024, 0.4976],\n",
      "        [0.5109, 0.4891],\n",
      "        [0.5094, 0.4906],\n",
      "        [0.5052, 0.4948],\n",
      "        [0.5169, 0.4831],\n",
      "        [0.5161, 0.4839],\n",
      "        [0.5316, 0.4684],\n",
      "        [0.5084, 0.4916],\n",
      "        [0.5090, 0.4910],\n",
      "        [0.5171, 0.4829],\n",
      "        [0.5307, 0.4693],\n",
      "        [0.5117, 0.4883],\n",
      "        [0.5297, 0.4703],\n",
      "        [0.5356, 0.4644],\n",
      "        [0.4974, 0.5026],\n",
      "        [0.5027, 0.4973],\n",
      "        [0.5288, 0.4712],\n",
      "        [0.5083, 0.4917],\n",
      "        [0.5303, 0.4697],\n",
      "        [0.5075, 0.4925],\n",
      "        [0.5260, 0.4740],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.4899, 0.5101],\n",
      "        [0.5072, 0.4928],\n",
      "        [0.5048, 0.4952],\n",
      "        [0.5126, 0.4874],\n",
      "        [0.5181, 0.4819],\n",
      "        [0.5043, 0.4957],\n",
      "        [0.5081, 0.4919],\n",
      "        [0.5421, 0.4579],\n",
      "        [0.4864, 0.5136],\n",
      "        [0.5176, 0.4824],\n",
      "        [0.4957, 0.5043],\n",
      "        [0.5098, 0.4902],\n",
      "        [0.5164, 0.4836],\n",
      "        [0.5379, 0.4621],\n",
      "        [0.5110, 0.4890],\n",
      "        [0.5275, 0.4725],\n",
      "        [0.5354, 0.4646],\n",
      "        [0.4987, 0.5013],\n",
      "        [0.4986, 0.5014],\n",
      "        [0.5355, 0.4645],\n",
      "        [0.5008, 0.4992],\n",
      "        [0.5212, 0.4788],\n",
      "        [0.5250, 0.4750],\n",
      "        [0.5118, 0.4882],\n",
      "        [0.5290, 0.4710],\n",
      "        [0.5005, 0.4995],\n",
      "        [0.5063, 0.4937],\n",
      "        [0.5093, 0.4907],\n",
      "        [0.4861, 0.5139],\n",
      "        [0.5231, 0.4769],\n",
      "        [0.5094, 0.4906],\n",
      "        [0.5252, 0.4748],\n",
      "        [0.5291, 0.4709],\n",
      "        [0.5035, 0.4965],\n",
      "        [0.5233, 0.4767],\n",
      "        [0.5316, 0.4684],\n",
      "        [0.5197, 0.4803],\n",
      "        [0.4897, 0.5103],\n",
      "        [0.5394, 0.4606],\n",
      "        [0.5254, 0.4746],\n",
      "        [0.5006, 0.4994],\n",
      "        [0.5018, 0.4982],\n",
      "        [0.5068, 0.4932],\n",
      "        [0.5127, 0.4873],\n",
      "        [0.5259, 0.4741],\n",
      "        [0.4973, 0.5027],\n",
      "        [0.5074, 0.4926],\n",
      "        [0.5162, 0.4838],\n",
      "        [0.5205, 0.4795],\n",
      "        [0.5218, 0.4782],\n",
      "        [0.5254, 0.4746],\n",
      "        [0.5173, 0.4827],\n",
      "        [0.4925, 0.5075],\n",
      "        [0.5345, 0.4655],\n",
      "        [0.4977, 0.5023]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork1(num_of_input_features=10)\n",
    "X = torch.rand(size=(100,10),dtype=torch.float32)\n",
    "y_predict = model(X)\n",
    "print(y_predict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610c9d3786a5bcd122c38aa183fd980592c5db79f4cee84c2a544f8f000107e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
