{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[[[0.9959, 0.6233, 0.7952, 0.8876, 0.4791],\n",
      "          [0.4771, 0.6017, 0.6354, 0.5171, 0.7281],\n",
      "          [0.6736, 0.3320, 0.5155, 0.3586, 0.1952],\n",
      "          [0.2467, 0.1193, 0.4496, 0.2860, 0.0805]],\n",
      "\n",
      "         [[0.9386, 0.1170, 0.3307, 0.3348, 0.4056],\n",
      "          [0.2674, 0.9489, 0.6987, 0.2693, 0.0271],\n",
      "          [0.9754, 0.6091, 0.0607, 0.4860, 0.3923],\n",
      "          [0.1292, 0.0024, 0.7684, 0.3059, 0.4738]],\n",
      "\n",
      "         [[0.4505, 0.4323, 0.6591, 0.3437, 0.7971],\n",
      "          [0.2032, 0.6988, 0.1278, 0.0558, 0.7195],\n",
      "          [0.5669, 0.0681, 0.9151, 0.8431, 0.7289],\n",
      "          [0.7627, 0.3015, 0.2426, 0.8423, 0.6755]]],\n",
      "\n",
      "\n",
      "        [[[0.5554, 0.1653, 0.6469, 0.4798, 0.7879],\n",
      "          [0.6348, 0.9374, 0.4714, 0.8439, 0.2925],\n",
      "          [0.8287, 0.7789, 0.7256, 0.4816, 0.5100],\n",
      "          [0.2414, 0.9486, 0.2341, 0.2894, 0.4122]],\n",
      "\n",
      "         [[0.6146, 0.4726, 0.7810, 0.9279, 0.1455],\n",
      "          [0.1664, 0.0396, 0.9354, 0.0778, 0.9027],\n",
      "          [0.0020, 0.6663, 0.8229, 0.1453, 0.7463],\n",
      "          [0.7065, 0.5371, 0.0462, 0.4034, 0.4119]],\n",
      "\n",
      "         [[0.8485, 0.9365, 0.7519, 0.3338, 0.7391],\n",
      "          [0.4915, 0.8361, 0.1687, 0.1033, 0.7170],\n",
      "          [0.2930, 0.0739, 0.8471, 0.8032, 0.8522],\n",
      "          [0.5057, 0.2494, 0.7186, 0.9267, 0.5244]]]])\n"
     ]
    }
   ],
   "source": [
    "# generall 3 is mostly used and then 2 d\n",
    "# 4d tensor is just 3d tensor with last dimension just as array \n",
    "t = torch.rand(size=(2,3,4,5))\n",
    "# t = torch.rand(size=(2,3,4))\n",
    "\n",
    "print(f'tensor: {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# giving data type to the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:tensor([[0.0581, 0.4171],\n",
      "        [0.0068, 0.1852]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(size=(2,2),dtype=torch.float32)\n",
    "print(f\"tensor:{t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating zeros and ones tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors: tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros(size=(2,3,4),dtype=torch.float16)\n",
    "print(f\"tensors: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(size=(2,3,4),dtype=torch.float64)\n",
    "print(f\"tensor: {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting tensor basic properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[[ 1.,  2.,  3.],\n",
      "         [ 2.,  3.,  4.],\n",
      "         [ 3.,  4.,  5.],\n",
      "         [12., 24., 53.]],\n",
      "\n",
      "        [[ 1.,  3.,  2.],\n",
      "         [10.,  3.,  5.],\n",
      "         [10., 13., 13.],\n",
      "         [32., 53., 45.]],\n",
      "\n",
      "        [[ 1.,  3.,  4.],\n",
      "         [11.,  5., 10.],\n",
      "         [16., 33., 53.],\n",
      "         [34., 53., 34.]],\n",
      "\n",
      "        [[ 2.,  6.,  6.],\n",
      "         [69., 94.,  1.],\n",
      "         [16., 78., 43.],\n",
      "         [34., 56., 89.]],\n",
      "\n",
      "        [[ 0., 34.,  4.],\n",
      "         [48.,  9., 14.],\n",
      "         [16., 34., 54.],\n",
      "         [ 3., 32., 32.]]])\n",
      "shape: torch.Size([5, 4, 3])\n",
      "rank: tensor([3, 3, 3, 3, 3])\n",
      "device:cpu\n",
      "Datatype of tensor: torch.float32\n",
      "size:torch.Size([5, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# python list \n",
    "a= [\n",
    "    [[1,2,3],[2,3,4],[3,4,5],[12,24,53]],\n",
    "    [[1,3,2],[10,3,5],[10,13,13],[32,53,45]],\n",
    "    [[1,3,4],[11,5,10],[16,33,53],[34,53,34]],\n",
    "    [[2,6,6],[69,94,1],[16,78,43],[34,56,89]],\n",
    "    [[0,34,4],[48,9,14],[16,34,54],[3,32,32]],\n",
    "    ]\n",
    "# t = torch.tensor(data=t,dtype=torch.float,device=\"cuda\")\n",
    "t = torch.tensor(data=a,dtype=torch.float,device=\"cpu\")\n",
    "\n",
    "print(f\"tensor: {t}\")\n",
    "print(f\"shape: {t.shape}\")\n",
    "print(f\"rank: {torch.linalg.matrix_rank(t)}\")\n",
    "print(f\"device:{t.device}\")\n",
    "print(f\"Datatype of tensor: {t.dtype}\")\n",
    "print(f\"size:{t.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# operation vs in tensor operation\n",
    " these all perform element wise division\n",
    "```\n",
    "+ or add\n",
    "- or sub\n",
    "* or mul \n",
    "/ or div \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c after add operation :tensor([[0.5824, 1.1766],\n",
      "        [0.4174, 0.8452]]) \n",
      "c after + operation :tensor([[0.5824, 1.1766],\n",
      "        [0.4174, 0.8452]])\n",
      "c before addition : tensor([[0.5824, 1.1766],\n",
      "        [0.4174, 0.8452]])\n",
      "c after addition:tensor([[0.8847, 2.0642],\n",
      "        [0.4756, 1.3271]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2,2),dtype=torch.float32)\n",
    "b = torch.rand((2,2),dtype=torch.float32)\n",
    "\n",
    "# operation\n",
    "c = torch.add(a,b)\n",
    "\n",
    "print(f\"c after add operation :{c} \")\n",
    "c = a + b \n",
    "print(f\"c after + operation :{c}\")\n",
    "\n",
    "\n",
    "# in value operation\n",
    "# every underscore(_) is in value operation\n",
    "print(f\"c before addition : {c}\")\n",
    "\n",
    "c.add_(b)\n",
    "print(f\"c after addition:{c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:tensor([[ 5., 10., 15.],\n",
      "        [20., 25., 30.]])\n",
      "b : tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "c:tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a = [[5,10,15],[20,25,30]]\n",
    "\n",
    "a = torch.tensor(data=a,dtype=torch.float32)\n",
    "print(f\"a:{a}\")\n",
    "b = torch.ones(2,3,dtype=torch.float32)\n",
    "b = b * 5\n",
    "print(f\"b : {b}\")\n",
    "c = a / b\n",
    "# c = torch.div(a,b)\n",
    "print(f\"c:{c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the tensor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,3],[3],[[4,5]]]\n",
    "# you cannot have different lengths of x,y,z on tensors\n",
    "# ERROR: expected sequence of length 2 at dim 1 (got 1)\n",
    "# a = torch.tensor(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3227, 0.6328, 0.1937],\n",
      "         [0.4060, 0.1921, 0.7416],\n",
      "         [0.4749, 0.6522, 0.9879]],\n",
      "\n",
      "        [[0.6943, 0.6406, 0.7844],\n",
      "         [0.3685, 0.0216, 0.8882],\n",
      "         [0.7567, 0.8127, 0.4155]],\n",
      "\n",
      "        [[0.5506, 0.2698, 0.7548],\n",
      "         [0.2157, 0.2743, 0.8858],\n",
      "         [0.5782, 0.7146, 0.1247]],\n",
      "\n",
      "        [[0.7935, 0.5813, 0.6807],\n",
      "         [0.1123, 0.5562, 0.9028],\n",
      "         [0.7809, 0.1615, 0.3804]]])\n",
      "a[0] is starting surface:\n",
      " tensor([[0.3227, 0.6328, 0.1937],\n",
      "        [0.4060, 0.1921, 0.7416],\n",
      "        [0.4749, 0.6522, 0.9879]])\n",
      "a[0,0] is the first row of a[0] surface:\n",
      " tensor([0.3227, 0.6328, 0.1937])\n",
      "a[0,0,0] is the first element of a[0,0] row:\n",
      " 0.3226662278175354\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(size=(4,3,3),dtype=torch.float32)\n",
    "print(a)\n",
    "# give index to access starting from zero\n",
    "#NOTE: for better understanding \n",
    "# view as higher dimension tensor as the element of the 3d tensor \n",
    "print(f\"a[0] is starting surface:\\n {a[0]}\")\n",
    "\n",
    "print(f\"a[0,0] is the first row of a[0] surface:\\n {a[0,0]}\")\n",
    "\n",
    "print(f\"a[0,0,0] is the first element of a[0,0] row:\\n {a[0,0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total element in tensor : 24\n",
      "x:\n",
      " tensor([[[0.0864, 0.4451, 0.7590, 0.2011],\n",
      "         [0.4279, 0.4783, 0.3981, 0.1847],\n",
      "         [0.7718, 0.0858, 0.7004, 0.9996]],\n",
      "\n",
      "        [[0.8075, 0.3373, 0.2590, 0.7142],\n",
      "         [0.9869, 0.2954, 0.0187, 0.8719],\n",
      "         [0.7840, 0.0431, 0.1601, 0.2844]]])\n",
      "y:\n",
      " tensor([[0.0864, 0.4451, 0.7590],\n",
      "        [0.2011, 0.4279, 0.4783],\n",
      "        [0.3981, 0.1847, 0.7718],\n",
      "        [0.0858, 0.7004, 0.9996],\n",
      "        [0.8075, 0.3373, 0.2590],\n",
      "        [0.7142, 0.9869, 0.2954],\n",
      "        [0.0187, 0.8719, 0.7840],\n",
      "        [0.0431, 0.1601, 0.2844]])\n",
      "b:\n",
      " tensor([[[0.0864, 0.4451, 0.7590, 0.2011, 0.4279, 0.4783],\n",
      "         [0.3981, 0.1847, 0.7718, 0.0858, 0.7004, 0.9996]],\n",
      "\n",
      "        [[0.8075, 0.3373, 0.2590, 0.7142, 0.9869, 0.2954],\n",
      "         [0.0187, 0.8719, 0.7840, 0.0431, 0.1601, 0.2844]]])\n",
      "size or shapeof b:torch.Size([2, 2, 6]) or torch.Size([2, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(2,3,4))\n",
    "num = torch.numel(x)\n",
    "print(f\"number of total element in tensor : {num}\")\n",
    "\n",
    "# -1 means auto find the number of surface\n",
    "a = x.view(-1,int(num/8))\n",
    "# b = x.view(-1,-1,2) # RuntimeError: only one dimension can be inferred\n",
    "b = x.view(-1,2,6)\n",
    "print(f\"x:\\n {x}\")\n",
    "print(f\"y:\\n {a}\")\n",
    "print(f\"b:\\n {b}\")\n",
    "print(f\"size or shapeof b:{b.shape} or {b.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy into  tensor and vice verso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is tensor:\n",
      " tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "b is numpy:\n",
      " [[[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]]\n",
      "type of a: <class 'torch.Tensor'> and type of b: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(size=(2,3,5))\n",
    "\n",
    "# coverting tensor to numpy\n",
    "b = a.numpy()\n",
    "\n",
    "# now you can do all attributes of numpy and call any method supported by numpy\n",
    "print(f\"a is tensor:\\n {a}\")\n",
    "print(f\"b is numpy:\\n {b}\")\n",
    "print(f\"type of a: {type(a)} and type of b: {type(b)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## both the numpy array and the tensor share the same memory location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________before________________________\n",
      "a: tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "b: [[[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]]\n",
      "________________________after torch operation _____________\n",
      "a:tensor([[[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]]])\n",
      "b:[[[2. 2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2. 2.]]\n",
      "\n",
      " [[2. 2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2. 2.]\n",
      "  [2. 2. 2. 2. 2.]]]\n",
      "________________________after numpy operation memory is not _____________\n",
      "a:tensor([[[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2., 2.]]])\n",
      "b:[[[3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]]]\n",
      "________________________after torch operation _____________\n",
      "a:tensor([[[25., 25., 25., 25., 25.],\n",
      "         [25., 25., 25., 25., 25.],\n",
      "         [25., 25., 25., 25., 25.]],\n",
      "\n",
      "        [[25., 25., 25., 25., 25.],\n",
      "         [25., 25., 25., 25., 25.],\n",
      "         [25., 25., 25., 25., 25.]]])\n",
      "b:[[[3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]]\n",
      "\n",
      " [[3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]\n",
      "  [3. 3. 3. 3. 3.]]]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(size=(2,3,5))\n",
    "\n",
    "# coverting tensor to numpy\n",
    "b = a.numpy()\n",
    "print(\"_______________________before________________________\")\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "# after torch operation\n",
    "a.add_(1)\n",
    "print(\"________________________after torch operation _____________\")\n",
    "print(f\"a:{a}\")\n",
    "print(f\"b:{b}\")\n",
    "\n",
    "# after numpy operation\n",
    "# NOTE: after numpy operation the memory is not shared\n",
    "b = b + 1\n",
    "print(\"________________________after numpy operation memory is not _____________\")\n",
    "print(f\"a:{a}\")\n",
    "print(f\"b:{b}\")\n",
    "\n",
    "\n",
    "# after torch operation\n",
    "a.add_(23)\n",
    "print(\"________________________after torch operation _____________\")\n",
    "print(f\"a:{a}\")\n",
    "print(f\"b:{b}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting the numpy to tensor \n",
    "\n",
    "\n",
    "and don't share same memory location too if they uses cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------before----------------------\n",
      "a: [[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "b: tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]], dtype=torch.float64)\n",
      "---------------------------after torch operation----------------------\n",
      "a: [[24. 24. 24. 24. 24.]\n",
      " [24. 24. 24. 24. 24.]]\n",
      "b: tensor([[24., 24., 24., 24., 24.],\n",
      "        [24., 24., 24., 24., 24.]], dtype=torch.float64)\n",
      "---------------------------after numpy operation memory is not shared----------------------\n",
      "a: [[25. 25. 25. 25. 25.]\n",
      " [25. 25. 25. 25. 25.]]\n",
      "b: tensor([[24., 24., 24., 24., 24.],\n",
      "        [24., 24., 24., 24., 24.]], dtype=torch.float64)\n",
      "---------------------------after torch operation----------------------\n",
      "a: [[25. 25. 25. 25. 25.]\n",
      " [25. 25. 25. 25. 25.]]\n",
      "b: tensor([[44., 44., 44., 44., 44.],\n",
      "        [44., 44., 44., 44., 44.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((2,5))\n",
    "\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "print(\"---------------------------before----------------------\")\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "# operation on torch\n",
    "b.add_(23)\n",
    "\n",
    "\n",
    "print(\"---------------------------after torch operation----------------------\")\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "# operation on numpy\n",
    "a = a + 1\n",
    "\n",
    "print(\"---------------------------after numpy operation memory is not shared----------------------\")\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "# operation on torch\n",
    "b.add_(20)\n",
    "\n",
    "\n",
    "print(\"---------------------------after torch operation----------------------\")\n",
    "print(f\"a: {a}\")\n",
    "print(f\"b: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the cuda device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    a = torch.rand((2,3),device=device)\n",
    "    # b is iniatially used in the cpu\n",
    "    b = torch.rand((2,3))\n",
    "    # b is now moved to gpu(cuda)\n",
    "    b = b.to(device)\n",
    "    \n",
    "    c = a + b\n",
    "\n",
    "    # a,b,c cannot be converted to numpy\n",
    "    # a,b,c is used loaded in cuda\n",
    "    # c = c.numpy() # error\n",
    "\n",
    "    # to  convert to numpy array you need to use cpu\n",
    "\n",
    "    c = c.to(\"cpu\")\n",
    "    c = c.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requires_grads = True\n",
    "for those which needs to be optimized and need to calculate gradient for those variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((2,3),requires_grad=True)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "610c9d3786a5bcd122c38aa183fd980592c5db79f4cee84c2a544f8f000107e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
